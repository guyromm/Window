<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Perspective-Correct 3D Corridor</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            background: #000;
            overflow: hidden;
            font-family: 'Courier New', monospace;
        }

        canvas {
            display: block;
            width: 100vw;
            height: 100vh;
        }

        #controls {
            position: fixed;
            top: 20px;
            left: 20px;
            background: rgba(0, 0, 0, 0.8);
            padding: 15px;
            border-radius: 5px;
            border: 1px solid #00ff00;
            color: #00ff00;
            font-size: 12px;
            line-height: 1.4;
            z-index: 1000;
            min-width: 300px;
        }

        #video-container {
            position: fixed;
            top: 20px;
            right: 20px;
            width: 200px;
            height: 150px;
            border: 1px solid #00ff00;
            z-index: 1000;
        }

        #video {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        #canvas-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        button {
            background: #00ff00;
            color: #000;
            border: none;
            padding: 8px 16px;
            font-family: inherit;
            cursor: pointer;
            margin: 2px;
            border-radius: 3px;
            font-size: 11px;
        }

        button:hover {
            background: #00cc00;
        }

        .status {
            color: #ffff00;
            margin-bottom: 8px;
        }
    </style>
</head>
<body>
    <canvas id="glCanvas"></canvas>

    <div id="controls">
        <div class="status">Head Tracking: <span id="trackingStatus">Off</span></div>
        <div>Head X: <span id="headX">0.0</span> cm</div>
        <div>Head Y: <span id="headY">0.0</span> cm</div>
        <div>Head Z: <span id="headZ">60.0</span> cm</div>
        <div>Face Detected: <span id="faceDetected">No</span></div>
        <div style="margin-top: 10px;">
            <button onclick="toggleHeadTracking()">Start Head Tracking</button>
            <button onclick="calibrateDistance()">Calibrate Distance</button>
        </div>
        <div style="margin-top: 10px; font-size: 10px; color: #888;">
            Move your head to see perspective change!<br>
            Calibrate distance for better accuracy.
        </div>
    </div>

    <div id="video-container">
        <video id="video" autoplay muted></video>
        <canvas id="canvas-overlay"></canvas>
    </div>

    <!-- MediaPipe Face Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js"></script>

    <script>
        // WebGL and 3D scene variables
        let gl;
        let program;
        let positionLocation;
        let colorLocation;
        let mvpLocation;
        let colorBuffer;

        // Head tracking variables
        let faceDetection;
        let camera;
        let isHeadTracking = false;
        let baselineFaceWidth = null;
        let calibratedDistance = 50;

        // Head position (in cm, relative to camera)
        let headPosition = { x: 0, y: 0, z: 50 };

        // Smoothing variables for jitter reduction
        const positionHistory = [];
        const SMOOTHING_WINDOW_MS = 200; // 1/5 second averaging window
        let lastPositionUpdateTime = Date.now();

        const video = document.getElementById('video');
        const overlayCanvas = document.getElementById('canvas-overlay');
        const overlayCtx = overlayCanvas.getContext('2d');

        // Screen dimensions (assuming laptop screen) - reduced for more dramatic perspective effect
        const SCREEN_WIDTH_CM = 20;  // Smaller virtual screen for more dramatic effect
        const SCREEN_HEIGHT_CM = 15; // Smaller virtual screen for more dramatic effect

        // Initialize WebGL
        function initWebGL() {
            const canvas = document.getElementById('glCanvas');
            gl = canvas.getContext('webgl');

            if (!gl) {
                alert('WebGL not supported');
                return false;
            }

            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);

            // Vertex shader
            const vertexShaderSource = `
                attribute vec3 position;
                attribute vec3 color;
                uniform mat4 mvpMatrix;
                varying vec3 vColor;

                void main() {
                    gl_Position = mvpMatrix * vec4(position, 1.0);
                    vColor = color;
                }
            `;

            // Fragment shader
            const fragmentShaderSource = `
                precision mediump float;
                varying vec3 vColor;

                void main() {
                    gl_FragColor = vec4(vColor, 1.0);
                }
            `;

            // Create and compile shaders
            const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
            const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
            program = createProgram(gl, vertexShader, fragmentShader);

            if (!program) {
                console.error('Failed to create shader program');
                return false;
            }

            gl.useProgram(program);

            positionLocation = gl.getAttribLocation(program, 'position');
            colorLocation = gl.getAttribLocation(program, 'color');
            mvpLocation = gl.getUniformLocation(program, 'mvpMatrix');

            gl.enableVertexAttribArray(positionLocation);
            gl.enableVertexAttribArray(colorLocation);

            colorBuffer = gl.createBuffer();

            return true;
        }

        function createShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);

            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error('Shader compilation error:', gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }
            return shader;
        }

        function createProgram(gl, vertexShader, fragmentShader) {
            const program = gl.createProgram();
            gl.attachShader(program, vertexShader);
            gl.attachShader(program, fragmentShader);
            gl.linkProgram(program);

            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error('Program linking error:', gl.getProgramInfoLog(program));
                gl.deleteProgram(program);
                return null;
            }
            return program;
        }

        // Matrix operations
        function multiply(a, b) {
            const result = new Float32Array(16);
            for (let i = 0; i < 4; i++) {
                for (let j = 0; j < 4; j++) {
                    result[i * 4 + j] =
                        a[i * 4 + 0] * b[0 * 4 + j] +
                        a[i * 4 + 1] * b[1 * 4 + j] +
                        a[i * 4 + 2] * b[2 * 4 + j] +
                        a[i * 4 + 3] * b[3 * 4 + j];
                }
            }
            return result;
        }

        function createPerspectiveMatrix(left, right, bottom, top, near, far) {
            const matrix = new Float32Array(16);
            matrix[0] = (2 * near) / (right - left);
            matrix[1] = 0;
            matrix[2] = (right + left) / (right - left);
            matrix[3] = 0;
            matrix[4] = 0;
            matrix[5] = (2 * near) / (top - bottom);
            matrix[6] = (top + bottom) / (top - bottom);
            matrix[7] = 0;
            matrix[8] = 0;
            matrix[9] = 0;
            matrix[10] = -(far + near) / (far - near);
            matrix[11] = -(2 * far * near) / (far - near);
            matrix[12] = 0;
            matrix[13] = 0;
            matrix[14] = -1;
            matrix[15] = 0;
            return matrix;
        }

        function createViewMatrix(eyeX, eyeY, eyeZ) {
            // Translation matrix for camera position - moves the world opposite to head movement
            return new Float32Array([
                1, 0, 0, 0,
                0, 1, 0, 0,
                0, 0, 1, 0,
                -eyeX, -eyeY, -eyeZ, 1
            ]);
        }

        function createPerspectiveCorrectedMatrix(headX, headY, headZ) {
            const near = 1.0;
            const far = 1000.0;

            // For proper "window" perspective:
            // Moving head right should show more of the left side
            // Moving head away should make corridor appear farther/smaller

            // FIXED: Invert the Z relationship - use a reference distance with weaker effect
            const referenceZ = 50; // Reference distance
            const zEffect = 0.3; // Weaker Z effect (30% instead of 100%)
            const zScale = 1 + (referenceZ / headZ - 1) * zEffect; // Much weaker Z scaling

            // Calculate the view frustum based on head position relative to screen
            // AMPLIFY head X,Y effects for dramatic perspective changes
            const amplifiedHeadX = headX * 2.0; // Double the lateral effect
            const amplifiedHeadY = headY * 2.0; // Double the vertical effect

            const left = (-SCREEN_WIDTH_CM/2 + amplifiedHeadX) * near * zScale / referenceZ;
            const right = (SCREEN_WIDTH_CM/2 + amplifiedHeadX) * near * zScale / referenceZ;
            const bottom = (-SCREEN_HEIGHT_CM/2 - amplifiedHeadY) * near * zScale / referenceZ;  // Original was correct
            const top = (SCREEN_HEIGHT_CM/2 - amplifiedHeadY) * near * zScale / referenceZ;      // Original was correct

            return createPerspectiveMatrix(left, right, bottom, top, near, far);
        }

        function render() {
            gl.clearColor(0.1, 0.1, 0.2, 1.0);
            gl.clear(gl.COLOR_BUFFER_BIT);

            gl.useProgram(program);

            // Create perspective projection matrix
            const projectionMatrix = createPerspectiveCorrectedMatrix(
                headPosition.x,
                headPosition.y,
                headPosition.z
            );

            // Create view matrix that moves the camera based on head position - VERY SUBTLE movement
            const viewMatrix = createViewMatrix(
                headPosition.x / 25,  // Very subtle camera movement (25x less)
                headPosition.y / 25,  // Very subtle camera movement (25x less)
                0                     // Keep camera at screen plane
            );

            // Create corridor geometry - positioned behind the screen
            const corridorWidth = 30;
            const corridorHeight = 20;
            const corridorDepth = 150; // Much longer corridor
            const corridorStart = -5; // Start corridor closer behind screen
            const corridorNear = 10; // Near wall position (behind viewer)

            const vertices = [
                // Near wall (behind viewer)
                -corridorWidth/2, -corridorHeight/2, corridorNear,  // 0: bottom-left near wall
                 corridorWidth/2, -corridorHeight/2, corridorNear,  // 1: bottom-right near wall
                 corridorWidth/2,  corridorHeight/2, corridorNear,  // 2: top-right near wall
                -corridorWidth/2,  corridorHeight/2, corridorNear,  // 3: top-left near wall

                // Middle corridor (behind screen)
                -corridorWidth/2, -corridorHeight/2, corridorStart,  // 4: bottom-left middle
                 corridorWidth/2, -corridorHeight/2, corridorStart,  // 5: bottom-right middle
                 corridorWidth/2,  corridorHeight/2, corridorStart,  // 6: top-right middle
                -corridorWidth/2,  corridorHeight/2, corridorStart,  // 7: top-left middle

                // Far corridor end - much smaller for dramatic perspective
                -corridorWidth/6, -corridorHeight/6, corridorStart - corridorDepth,  // 8: bottom-left far
                 corridorWidth/6, -corridorHeight/6, corridorStart - corridorDepth,  // 9: bottom-right far
                 corridorWidth/6,  corridorHeight/6, corridorStart - corridorDepth,  // 10: top-right far
                -corridorWidth/6,  corridorHeight/6, corridorStart - corridorDepth   // 11: top-left far
            ];

            const indices = [
                // Near wall rectangle
                0, 1,  1, 2,  2, 3,  3, 0,
                // Perspective lines from near to middle
                0, 4,  // bottom-left near to middle
                1, 5,  // bottom-right near to middle
                2, 6,  // top-right near to middle
                3, 7,  // top-left near to middle
                // Perspective lines from middle to far
                4, 8,   // bottom-left to far bottom-left
                5, 9,   // bottom-right to far bottom-right
                6, 10,  // top-right to far top-right
                7, 11,  // top-left to far top-left
                // Far wall rectangle
                8, 9,  9, 10,  10, 11,  11, 8
            ];

            // Create and bind position buffer
            const positionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);
            gl.vertexAttribPointer(positionLocation, 3, gl.FLOAT, false, 0, 0);

            // Set white color for all vertices
            const colors = new Array(vertices.length).fill(1); // All white
            gl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(colors), gl.STATIC_DRAW);
            gl.vertexAttribPointer(colorLocation, 3, gl.FLOAT, false, 0, 0);

            // Combine projection and view matrices
            const mvpMatrix = multiply(projectionMatrix, viewMatrix);

            // Set MVP matrix
            gl.uniformMatrix4fv(mvpLocation, false, mvpMatrix);

            // Draw corridor
            const indexBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);
            gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array(indices), gl.STATIC_DRAW);
            gl.drawElements(gl.LINES, indices.length, gl.UNSIGNED_SHORT, 0);
        }

        // Head tracking functions
        function initializeFaceDetection() {
            faceDetection = new FaceDetection({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`;
                }
            });

            faceDetection.setOptions({
                model: 'short',
                minDetectionConfidence: 0.5,
            });

            faceDetection.onResults(onFaceResults);

            camera = new Camera(video, {
                onFrame: async () => {
                    if (isHeadTracking) {
                        await faceDetection.send({image: video});
                    }
                },
                width: 320,
                height: 240
            });
        }

        function onFaceResults(results) {
            overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            if (results.detections && results.detections.length > 0) {
                const detection = results.detections[0];
                const bbox = detection.boundingBox;
                lastDetectionBbox = bbox; // Store for calibration

                const faceX = bbox.xCenter * overlayCanvas.width;
                const faceY = bbox.yCenter * overlayCanvas.height;
                const faceWidth = bbox.width * overlayCanvas.width;
                const faceHeight = bbox.height * overlayCanvas.height;

                // Draw face detection
                overlayCtx.strokeStyle = '#00ff00';
                overlayCtx.lineWidth = 2;
                overlayCtx.strokeRect(
                    faceX - faceWidth/2,
                    faceY - faceHeight/2,
                    faceWidth,
                    faceHeight
                );

                // Update head position
                updateHeadPosition(faceX, faceY, faceWidth, faceHeight);
                document.getElementById('faceDetected').textContent = 'Yes';
            } else {
                document.getElementById('faceDetected').textContent = 'No';
                lastDetectionBbox = null;
            }
        }

        function updateHeadPosition(faceX, faceY, faceWidth, faceHeight) {
            const videoWidth = overlayCanvas.width;
            const videoHeight = overlayCanvas.height;
            const currentTime = Date.now();

            // Auto-calibrate on first detection if not already calibrated
            if (!baselineFaceWidth) {
                baselineFaceWidth = faceWidth;
                console.log('Auto-calibrated baseline face width:', baselineFaceWidth);
            }

            // Calculate raw position values
            const newDistance = (baselineFaceWidth / faceWidth) * calibratedDistance;
            const horizontalPixelOffset = faceX - (videoWidth / 2);
            const verticalPixelOffset = faceY - (videoHeight / 2);
            const rawX = (horizontalPixelOffset / videoWidth) * (SCREEN_WIDTH_CM * 5.0);
            const rawY = (verticalPixelOffset / videoHeight) * (SCREEN_HEIGHT_CM * 5.0);  // Removed negation to fix inversion

            // Add current position to history
            positionHistory.push({
                x: rawX,
                y: rawY,
                z: newDistance,
                timestamp: currentTime
            });

            // Remove old positions outside the smoothing window
            const cutoffTime = currentTime - SMOOTHING_WINDOW_MS;
            while (positionHistory.length > 0 && positionHistory[0].timestamp < cutoffTime) {
                positionHistory.shift();
            }

            // Calculate smoothed position using weighted average (newer samples have more weight)
            let totalWeight = 0;
            let smoothedX = 0, smoothedY = 0, smoothedZ = 0;

            positionHistory.forEach((pos, index) => {
                // Linear weight based on age (newer = higher weight)
                const age = currentTime - pos.timestamp;
                const weight = 1 - (age / SMOOTHING_WINDOW_MS);

                smoothedX += pos.x * weight;
                smoothedY += pos.y * weight;
                smoothedZ += pos.z * weight;
                totalWeight += weight;
            });

            // Apply smoothed values if we have enough data
            if (totalWeight > 0) {
                headPosition.x = smoothedX / totalWeight;
                headPosition.y = smoothedY / totalWeight;
                headPosition.z = smoothedZ / totalWeight;
            } else {
                // Fallback to raw values if no history
                headPosition.x = rawX;
                headPosition.y = rawY;
                headPosition.z = newDistance;
            }

            // Debug logging (less frequent)
            if (currentTime - lastPositionUpdateTime > 100) {
                console.log(`Smoothed position - X: ${headPosition.x.toFixed(1)}, Y: ${headPosition.y.toFixed(1)}, Z: ${headPosition.z.toFixed(1)}`);
                lastPositionUpdateTime = currentTime;
            }

            // Update display
            document.getElementById('headX').textContent = headPosition.x.toFixed(1);
            document.getElementById('headY').textContent = headPosition.y.toFixed(1);
            document.getElementById('headZ').textContent = headPosition.z.toFixed(1);
        }

        async function toggleHeadTracking() {
            if (!isHeadTracking) {
                try {
                    await camera.start();
                    isHeadTracking = true;
                    document.getElementById('trackingStatus').textContent = 'On';

                    overlayCanvas.width = video.videoWidth || 320;
                    overlayCanvas.height = video.videoHeight || 240;
                } catch (err) {
                    console.error('Failed to start camera:', err);
                    document.getElementById('trackingStatus').textContent = 'Error';
                }
            } else {
                camera.stop();
                isHeadTracking = false;
                document.getElementById('trackingStatus').textContent = 'Off';
                overlayCtx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            }
        }

        function calibrateDistance() {
            if (isHeadTracking && document.getElementById('faceDetected').textContent === 'Yes') {
                const userDistance = prompt('How far are you from the screen in cm?', '50');
                if (userDistance && !isNaN(userDistance)) {
                    // Get current face width from the last detection
                    const bbox = lastDetectionBbox;
                    if (bbox) {
                        const faceWidth = bbox.width * overlayCanvas.width;
                        baselineFaceWidth = faceWidth;
                        calibratedDistance = parseFloat(userDistance);
                        headPosition.z = calibratedDistance;
                        alert(`Distance calibrated to ${userDistance}cm`);
                    }
                }
            } else {
                alert('Please start head tracking and ensure your face is detected first');
            }
        }

        let lastDetectionBbox = null;

        // Animation loop
        function animate() {
            render();
            requestAnimationFrame(animate);
        }

        // Initialize everything
        window.addEventListener('load', function() {
            if (initWebGL()) {
                initializeFaceDetection();
                animate();
                // Auto-start head tracking
                setTimeout(() => {
                    toggleHeadTracking();
                }, 1000);
            }
        });

        // Handle window resize
        window.addEventListener('resize', function() {
            const canvas = document.getElementById('glCanvas');
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        });
    </script>
</body>
</html>